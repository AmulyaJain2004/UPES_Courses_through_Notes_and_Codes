{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f0af75",
   "metadata": {},
   "source": [
    "# Linear Regression Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c300d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64722fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_utils as mt\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffceebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.read_csv(r'./loan_data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842a9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ac487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtr(orig_col):\n",
    "    \n",
    "    mod_col=orig_col.str.replace('%','')\n",
    "    mod_col=pd.to_numeric(mod_col,errors='coerce')\n",
    "    \n",
    "    return mod_col\n",
    "    \n",
    "\n",
    "def fico(orig_col):\n",
    "    k=orig_col.str.split('-',expand=True)\n",
    "    \n",
    "    for i in [0,1]:\n",
    "        k[i]=pd.to_numeric(k[i],errors='coerce')\n",
    "    \n",
    "    mod_col=0.5*(k[0]+k[1])\n",
    "    \n",
    "    return mod_col\n",
    "    \n",
    "\n",
    "def el(orig_col):\n",
    "    \n",
    "    inter_col=orig_col.str.replace('10+ years','10',regex=False)\n",
    "    inter_col=inter_col.str.replace('< 1 year','0',regex=False)\n",
    "    inter_col=inter_col.str.replace('years','').str.replace('year','')\n",
    "    \n",
    "    mod_col=pd.to_numeric(inter_col,errors='coerce')\n",
    "    \n",
    "    return mod_col\n",
    "\n",
    "\n",
    "cat_to_dummies=['Loan.Length','Loan.Purpose','State','Home.Ownership']\n",
    "cat_to_num=['Amount.Requested','Open.CREDIT.Lines','Revolving.CREDIT.Balance']\n",
    "simple_num=['Monthly.Income','Inquiries.in.the.Last.6.Months']\n",
    "custom_func_dict={'Debt.To.Income.Ratio':dtr,'FICO.Range':fico,'Employment.Length':el}\n",
    "\n",
    "dp=mt.DataPipe(cat_to_dummies=cat_to_dummies,\n",
    "                 cat_to_num=cat_to_num,\n",
    "                 simple_num=simple_num,\n",
    "                 custom_func_dict=custom_func_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccceb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=dp.transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8826e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=data_train['Interest.Rate'].str.replace('%','').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b148f",
   "metadata": {},
   "source": [
    "# Estimating Model Coefficients with Closed Form Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a13a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_la=x_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd72cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_la.insert(0,'constant',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b96630",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t_x=np.dot(x_la.T,x_la)\n",
    "\n",
    "x_t_x_inv=np.linalg.inv(x_t_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f8fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t_x=np.dot(y_train.T,x_la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t_x\n",
    "\n",
    "w_la=np.dot(x_t_x_inv,y_t_x)\n",
    "\n",
    "w_la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f5137",
   "metadata": {},
   "source": [
    "# Estimating Model Coefficient with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3156b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mypred(x,w):\n",
    "    \n",
    "    y_hat=x@w\n",
    "    return(y_hat)\n",
    "\n",
    "\n",
    "def myerror(y,x,w):\n",
    "    \n",
    "    y_hat=mypred(x,w)\n",
    "    errors=y-y_hat\n",
    "    return(errors)\n",
    "\n",
    "\n",
    "def mycost(y,x,w):\n",
    "    \n",
    "    errors=myerror(y,x,w)\n",
    "    \n",
    "    cost=errors.T@errors\n",
    "    \n",
    "    return(cost)\n",
    "\n",
    "\n",
    "def gradient(y,x,w):\n",
    "    \n",
    "    errors=myerror(y,x,w)\n",
    "    grad=-x.T@errors/x.shape[0]\n",
    "    return(grad)\n",
    "\n",
    "def my_lr_sgd(y,x,learning_rate,num_steps):\n",
    "    \n",
    "    weights=np.zeros(x.shape[1])\n",
    "    decay_rate = 0.9\n",
    "    prev_cost = float('inf')\n",
    " \n",
    "    for i in np.arange(num_steps):\n",
    "        rand_ind=np.random.choice(range(x.shape[0]),100)\n",
    "        y_sub=y[rand_ind]\n",
    "        x_sub=x.iloc[rand_ind,:]\n",
    "        \n",
    "        gd=gradient(y_sub,x_sub,weights)\n",
    "        \n",
    "        weights -= learning_rate*gd\n",
    "        \n",
    "        curr_cost = mycost(y, x, weights)\n",
    "\n",
    "        # Stop if converged\n",
    "        if np.abs(prev_cost - curr_cost) < 1e-6:\n",
    "            print(f\"Converged at iteration {i}\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "        if i%20000==0:\n",
    "            print(i,curr_cost)\n",
    "            learning_rate*=decay_rate\n",
    "            \n",
    "        prev_cost = curr_cost\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1279c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycost(y_train,x_la,w_la)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e3775",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "w_j&=\\frac{{w_j}'}{\\sigma_j} \\quad \\forall j \\in \\{1,2,\\cdots,p\\}\\\\\n",
    "w_0&={w_0}'-\\sum_{j=1}^p\\frac{\\mu_j{w_j}'}{\\sigma_j}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0242d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_non_standardized_weights(scaler, standardized_weights):\n",
    "    # Extract mean and scale (standard deviation) from the StandardScaler object\n",
    "    means = scaler.mean_\n",
    "    scales = scaler.scale_\n",
    "\n",
    "    # Initialize the array to store the non-standardized weights\n",
    "    non_standardized_weights = np.zeros_like(standardized_weights)\n",
    "\n",
    "    # Compute the weights for the non-standardized data\n",
    "    # w_j_non_standardized = w_j_standardized / scale_j for j > 0\n",
    "    non_standardized_weights[1:] = standardized_weights[1:] / scales\n",
    "\n",
    "    # Adjust the intercept term (w_0)\n",
    "    w0_adjustment = np.sum((means * standardized_weights[1:]) / scales)\n",
    "    non_standardized_weights[0] = standardized_weights[0] - w0_adjustment\n",
    "\n",
    "    return non_standardized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_sd=pd.DataFrame(scaler.transform(x_train),columns=x_train.columns)\n",
    "x_sd.insert(0,'constant',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_sgd=my_lr_sgd(y_train,x_sd,.01,500000)\n",
    "# see how the cost improves fast initially and then as we reach towards the optimal point\n",
    "# progresss slows down, this goes on for awhile , lets be patient for 10-15 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ba786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_sgd=convert_to_non_standardized_weights(scaler,w_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc20241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycost(y_train,x_la,w_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd00a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see that we have been able to reach cost levels almost as good as closed form solution\n",
    "# try other optimisers that we discussed and see how those fare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5360cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip([1]+list(x_train.columns),list(w_la),list(w_sgd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79509e87",
   "metadata": {},
   "source": [
    "# sklearn estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4076bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c14af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_lr=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64136cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b91a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_sk=[sk_lr.intercept_]+list(sk_lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18574c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip([1]+list(x_train.columns),list(w_la),list(w_gd),w_sk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4044d247",
   "metadata": {},
   "source": [
    "# Lasso [Linear Regression with $l_1$ and $l_2$ Penalty ] with gradient descent\n",
    "\n",
    "code below can be used with some fixed value for penalty parameter $\\alpha$ with either $l_1$ or $l_2$ penalty at a time , do experiment around with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e48172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mypred(x, w):\n",
    "    y_hat = x @ w\n",
    "    return y_hat\n",
    "\n",
    "def myerror(y, x, w):\n",
    "    y_hat = mypred(x, w)\n",
    "    errors = y - y_hat\n",
    "    return errors\n",
    "\n",
    "def mycost(y, x, w, alpha=0.1, penalty='l2'):\n",
    "    \"\"\"\n",
    "    Computes the cost function with either L1 or L2 regularization.\n",
    "\n",
    "    Parameters:\n",
    "    - y: actual values\n",
    "    - x: input data\n",
    "    - w: weights\n",
    "    - alpha: regularization strength\n",
    "    - penalty: 'l1' for Lasso (L1) or 'l2' for Ridge (L2)\n",
    "\n",
    "    Returns:\n",
    "    - cost: the regularized cost function value\n",
    "    \"\"\"\n",
    "    errors = myerror(y, x, w)\n",
    "    \n",
    "    # Basic cost (squared error)\n",
    "    cost = errors.T @ errors / (2 * x.shape[0])\n",
    "    \n",
    "    # Apply either L1 or L2 penalty\n",
    "    if penalty == 'l1':\n",
    "        l1_penalty = np.sum(np.abs(w))\n",
    "        total_cost = cost + alpha * l1_penalty\n",
    "    elif penalty == 'l2':\n",
    "        l2_penalty = np.sum(w ** 2)\n",
    "        total_cost = cost + alpha * l2_penalty\n",
    "    else:\n",
    "        raise ValueError(\"Invalid penalty type. Use 'l1' or 'l2'.\")\n",
    "    \n",
    "    return total_cost\n",
    "\n",
    "def gradient(y, x, w, alpha=0.1, penalty='l2'):\n",
    "    \"\"\"\n",
    "    Computes the gradient with either L1 or L2 regularization.\n",
    "\n",
    "    Parameters:\n",
    "    - y: actual values\n",
    "    - x: input data\n",
    "    - w: weights\n",
    "    - alpha: regularization strength\n",
    "    - penalty: 'l1' for Lasso (L1) or 'l2' for Ridge (L2)\n",
    "\n",
    "    Returns:\n",
    "    - grad: the gradient of the cost function with L1 or L2 regularization\n",
    "    \"\"\"\n",
    "    errors = myerror(y, x, w)\n",
    "    \n",
    "    # Gradient of the error term\n",
    "    grad = -x.T @ errors / x.shape[0]\n",
    "    \n",
    "    # Apply either L1 or L2 regularization gradient\n",
    "    if penalty == 'l1':\n",
    "        l1_grad = np.sign(w)  # Subgradient for L1\n",
    "        total_grad = grad + alpha * l1_grad\n",
    "    elif penalty == 'l2':\n",
    "        l2_grad = 2 * w\n",
    "        total_grad = grad + alpha * l2_grad\n",
    "    else:\n",
    "        raise ValueError(\"Invalid penalty type. Use 'l1' or 'l2'.\")\n",
    "    \n",
    "    return total_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92844e08",
   "metadata": {},
   "source": [
    "## Ridge and Lasso [linear regression with $l_2$ and $l_1$ penalty] with sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeaa6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_ridge=np.linspace(1,100,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51107e71",
   "metadata": {},
   "source": [
    "these are the values of $\\alpha$ we want to start our experiment with. `GridSearchCV` scores all these values with cross validation and we can extract with function `ml_utils.report` which value combination scores the best. We need to pass the parameters values that we want to experiment with as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a89ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ridge={'alpha':alphas_ridge} # key values here need to match exactly as the argument in the modeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf75941",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ridge=Ridge() # this is the model for which we want to experiment with parameter values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_ridge=GridSearchCV(lr_ridge,\n",
    "               param_grid=params_ridge,\n",
    "               cv=10, # 10 fold cross validation \n",
    "               scoring='neg_mean_absolute_error', # all models are scored with this criterion\n",
    "               verbose=20, # higher number should print more info while fitting [currently doesnt work well with jupyter]\n",
    "               n_jobs=-1) # allows for parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d362e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_ridge.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b6882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.report(gs_ridge.cv_results_,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad94da80",
   "metadata": {},
   "source": [
    "we see that the best value for alpha is `49` , we can further finetune this is by exploring the close range around this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20358a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ridge={'alpha':np.linspace(48,50,25)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d5dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_ridge=GridSearchCV(lr_ridge,\n",
    "               param_grid=params_ridge,\n",
    "               cv=10, \n",
    "               scoring='neg_mean_absolute_error',\n",
    "               verbose=20, \n",
    "               n_jobs=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65cbca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_ridge.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80596d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.report(gs_ridge.cv_results_,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d3e88",
   "metadata": {},
   "source": [
    "we can build the model for best parameter values separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14966d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_final=Ridge(**{'alpha': 49})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43107d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_final.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0196876",
   "metadata": {},
   "source": [
    "look at the weights estimate , none of them have been suppressed to exactly zero , but you will do see many have been suppressed b ya large factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_wt_comparison=pd.DataFrame({'features':['bias']+list(x_train.columns),\n",
    "                                  'simple_model':w_sk,'ridge_wts':[ridge_final.intercept_]+list(ridge_final.coef_)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_wt_comparison['suppression_ratio_l2']=ridge_wt_comparison['simple_model']/ridge_wt_comparison['ridge_wts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_wt_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df007358",
   "metadata": {},
   "source": [
    "you can make prediction with the fitted model in a similar manner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a77794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_final.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e30c6a",
   "metadata": {},
   "source": [
    "if you want to make prediction on test, data, transform it first with the datapipe we had fitted earlier for the same data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad048a",
   "metadata": {},
   "source": [
    "now lets see how $l_1$ penalty affects things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b62785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c7a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_lasso=np.linspace(1,100,100)\n",
    "params_lasso={'alpha':alphas_lasso}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02539804",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_lasso=Lasso()\n",
    "gs_lasso=GridSearchCV(lr_lasso,\n",
    "               param_grid=params_lasso,\n",
    "               cv=10,\n",
    "               scoring='neg_mean_absolute_error',\n",
    "               verbose=20,\n",
    "               n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b0e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lasso.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.report(gs_lasso.cv_results_,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc3cc7",
   "metadata": {},
   "source": [
    "you can see here that the best value comes at the left edge, we can probably improve our results by expanding our experiment values on that side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b6387",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_lasso=Lasso()\n",
    "alphas_lasso=np.linspace(0,2,100)\n",
    "params_lasso={'alpha':alphas_lasso}\n",
    "gs_lasso=GridSearchCV(lr_lasso,\n",
    "               param_grid=params_lasso,\n",
    "               cv=10,\n",
    "               scoring='neg_mean_absolute_error',\n",
    "               verbose=20,\n",
    "               n_jobs=-1)\n",
    "gs_lasso.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd09c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.report(gs_lasso.cv_results_,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7b741",
   "metadata": {},
   "source": [
    "now we got a value inbetween the range, we will consider this as our final model for lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e9febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_final=Lasso(**{'alpha': 0.020202020202020204})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_final.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e099574",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_wt_comparison['lasso_wts']=[lasso_final.intercept_]+list(lasso_final.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_wt_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934722d",
   "metadata": {},
   "source": [
    "you can see that $l_1$ penalty has made many weights exactly zero, to count how many weights have been made exactly zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8888da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(lasso_final.coef_==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d365fff",
   "metadata": {},
   "source": [
    "we can actually remove those features and built the model without them "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7938e",
   "metadata": {},
   "source": [
    "# Data Prep for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb935fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_train=pd.read_csv(r'./bd_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caeaae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def children_to_num(col):\n",
    "    \n",
    "    num_col=col.str.replace('Zero','0')\n",
    "    num_col=num_col.str.replace('4+','4',regex=False)\n",
    "    num_col=pd.to_numeric(num_col,errors='coerce')\n",
    "    \n",
    "    return num_col\n",
    "\n",
    "def ab_to_num(col):\n",
    "    \n",
    "    col=col.str.replace('71+','71-71',regex=False)\n",
    "    k=col.str.split('-',expand=True)\n",
    "    \n",
    "    for i in [0,1]:\n",
    "        k[i]=pd.to_numeric(k[i],errors='coerce')\n",
    "        \n",
    "    num_col=0.5*(k[0]+k[1])\n",
    "    \n",
    "    return num_col\n",
    "\n",
    "def fi_to_num(col):\n",
    "    \n",
    "    col=col.replace({'<10,000, >= 8,000':9000, '>=35,000':35000, '<25,000, >=22,500':23750,\n",
    "       '<20,000, >=17,500':18750, '<12,500, >=10,000':11250, '<30,000, >=27,500':28750,\n",
    "       '<27,500, >=25,000':26250, '<17,500, >=15,000':16250, '<15,000, >=12,500':13750,\n",
    "       '<22,500, >=20,000':21250,'< 4,000': 4000, '< 8,000, >= 4,000':6000})\n",
    "    num_col=pd.to_numeric(col,errors='coerce')\n",
    "    \n",
    "    return num_col\n",
    "\n",
    "simple_numeric_cols=['year_last_moved','Average.Credit.Card.Transaction', 'Balance.Transfer',\n",
    "      'Term.Deposit', 'Life.Insurance', 'Medical.Insurance',\n",
    "      'Average.A.C.Balance', 'Personal.Loan', 'Investment.in.Mutual.Fund',\n",
    "      'Investment.Tax.Saving.Bond', 'Home.Loan', 'Online.Purchase.Amount','Investment.in.Commudity',\n",
    "      'Investment.in.Equity', 'Investment.in.Derivative',\n",
    "      'Portfolio.Balance']\n",
    "\n",
    "cat_to_dummies_cols=['status' , 'occupation' , 'occupation_partner' , 'home_status', 'self_employed',\n",
    "'self_employed_partner','TVarea','gender','region']\n",
    "\n",
    "custom_function_cols={'children':children_to_num,'age_band':ab_to_num,'family_income':fi_to_num}\n",
    "\n",
    "dp=mt.DataPipe(simple_num=simple_numeric_cols,\n",
    "                     cat_to_dummies=cat_to_dummies_cols,\n",
    "                     custom_func_dict=custom_function_cols)\n",
    "\n",
    "dp.fit(bd_train)\n",
    "\n",
    "x_train=dp.transform(bd_train)\n",
    "\n",
    "y_train=(bd_train['Revenue.Grid']==1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4667eb",
   "metadata": {},
   "source": [
    "## Logistic regression with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c74a44f",
   "metadata": {},
   "source": [
    "you can use following functions to implement gradient descent version of parameter estimation for logistic regression, few things to keep in mind \n",
    "\n",
    "* standardize your data before using gradient descent with any optimizer you have in mind \n",
    "* you can `de-standardize` your estimates of weights thus obtained using the function `convert_to_non_standardized_weights` that we wrote earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a99bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def mypred(x, w):\n",
    "    \"\"\"\n",
    "    Logistic regression prediction (sigmoid function).\n",
    "    \"\"\"\n",
    "    z = x @ w\n",
    "    y_hat = sigmoid(z)\n",
    "    return y_hat\n",
    "\n",
    "def myerror(y, x, w):\n",
    "    \"\"\"\n",
    "    Computes the prediction errors for logistic regression.\n",
    "    \"\"\"\n",
    "    y_hat = mypred(x, w)\n",
    "    errors = y - y_hat\n",
    "    return errors\n",
    "\n",
    "def mycost(y, x, w, alpha=0.1, penalty='none'):\n",
    "    \"\"\"\n",
    "    Computes the cost function for logistic regression with either no penalty, L1 or L2 regularization.\n",
    "\n",
    "    Parameters:\n",
    "    - y: actual values\n",
    "    - x: input data\n",
    "    - w: weights\n",
    "    - alpha: regularization strength\n",
    "    - penalty: 'none' for no regularization, 'l1' for Lasso, or 'l2' for Ridge\n",
    "\n",
    "    Returns:\n",
    "    - cost: the regularized cost function value\n",
    "    \"\"\"\n",
    "    m = x.shape[0]\n",
    "    y_hat = mypred(x, w)\n",
    "\n",
    "    # Logistic loss (cross-entropy loss)\n",
    "    log_loss = -np.mean(y * np.log(y_hat + 1e-15) + (1 - y) * np.log(1 - y_hat + 1e-15))\n",
    "\n",
    "    # Apply either L1 or L2 penalty, or no penalty\n",
    "    if penalty == 'none':\n",
    "        total_cost = log_loss\n",
    "    elif penalty == 'l1':\n",
    "        l1_penalty = np.sum(np.abs(w))\n",
    "        total_cost = log_loss + alpha * l1_penalty / m\n",
    "    elif penalty == 'l2':\n",
    "        l2_penalty = np.sum(w ** 2)\n",
    "        total_cost = log_loss + alpha * l2_penalty / (2 * m)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid penalty type. Use 'none', 'l1', or 'l2'.\")\n",
    "\n",
    "    return total_cost\n",
    "\n",
    "def gradient(y, x, w, alpha=0.1, penalty='none'):\n",
    "    \"\"\"\n",
    "    Computes the gradient for logistic regression with either no penalty, L1 or L2 regularization.\n",
    "\n",
    "    Parameters:\n",
    "    - y: actual values\n",
    "    - x: input data\n",
    "    - w: weights\n",
    "    - alpha: regularization strength\n",
    "    - penalty: 'none' for no regularization, 'l1' for Lasso, or 'l2' for Ridge\n",
    "\n",
    "    Returns:\n",
    "    - grad: the gradient of the cost function with no regularization, L1, or L2 regularization\n",
    "    \"\"\"\n",
    "    m = x.shape[0]\n",
    "    y_hat = mypred(x, w)\n",
    "\n",
    "    # Gradient of the logistic loss\n",
    "    grad = -x.T @ (y - y_hat) / m\n",
    "\n",
    "    # Apply regularization if specified\n",
    "    if penalty == 'none':\n",
    "        total_grad = grad\n",
    "    elif penalty == 'l1':\n",
    "        l1_grad = np.sign(w)  # Subgradient for L1\n",
    "        total_grad = grad + alpha * l1_grad / m\n",
    "    elif penalty == 'l2':\n",
    "        l2_grad = 2 * w\n",
    "        total_grad = grad + alpha * l2_grad / m\n",
    "    else:\n",
    "        raise ValueError(\"Invalid penalty type. Use 'none', 'l1', or 'l2'.\")\n",
    "\n",
    "    return total_grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0891d19b",
   "metadata": {},
   "source": [
    "## Logistic Regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd16716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a444762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_logr={'class_weight':['balanced',None],\n",
    "       'penalty':['l1','l2'] ,# this is not 11 eleven, its L1 [el-one] in lower case \n",
    "        'C':[.0001,.0005,.001,.005,.01,.05,0.1,2,5,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr=LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4904ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_logr=GridSearchCV(logr,\n",
    "               param_grid=params_logr,\n",
    "               scoring='roc_auc', # scoring here is roc_auc for its a binary classification problem\n",
    "               cv=10,\n",
    "               n_jobs=-1,\n",
    "               verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e121af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_logr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a7878",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.report(gs_logr.cv_results_,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_final=LogisticRegression(solver='liblinear',**{'C': 0.05, 'class_weight': 'balanced', 'penalty': 'l1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e5e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_final.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763ec6f",
   "metadata": {},
   "source": [
    "## predict probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e4a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default fitted model predicts probabilities for all the classes, and use the function predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364491fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_final.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff543597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to understand which set of probabilities belong to what class look at this attribute\n",
    "logr_final.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadc2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first probability belongs to class 0 and second to class 1 for each obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1_probs=logr_final.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4db780",
   "metadata": {},
   "source": [
    "## Predicting Hard Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to go to hard classes from these probabilities we need to find a proper threshold on the probabilities \n",
    "# lets find cutoff on the basis of KS , you can replicate the same with F_1 score also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7410b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "real=y_train\n",
    "score=logr_final.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43219599",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs=np.linspace(0.001,0.999,999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will calculate TP,TN,FP,FN for each cutoff and find corresponding KS value\n",
    "# we select the ideal cutoff for which ks is maximum\n",
    "# if there are multiple winners , we will simply go with the first one\n",
    "all_ks=[]\n",
    "\n",
    "for cutoff in cutoffs:\n",
    "    \n",
    "    # note that for each cutoff hard class predictions can be different\n",
    "    \n",
    "    predicted=(score>cutoff).astype(int) # this converts the True/False to 1/0\n",
    "    \n",
    "    TP=((real==1)&(predicted==1)).sum()\n",
    "    FP=((real==0)&(predicted==1)).sum()\n",
    "    TN=((real==0)&(predicted==0)).sum()\n",
    "    FN=((real==1)&(predicted==0)).sum()\n",
    "    \n",
    "    P=TP+FN\n",
    "    N=TN+FP\n",
    "    \n",
    "    ks=(TP/P)-(FP/N)\n",
    "    \n",
    "    all_ks.append(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(all_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d004fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cutoff=cutoffs[all_ks==max(all_ks)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_class_preds=(logr_final.predict_proba(x_train)[:,1]>selected_cutoff).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af591240",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db4e82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
